$$
V_\pi(s)=\mathbb{E}_\pi[G_t|S_t=s] \tag{1}
$$
Funkcja wartości stanu, dla każdego stanu $s$ zwraca oczekiwaną [[Skumulowana nagroda|skumulowaną nagrodę]] pod warunkiem, że agent znajduje się w stanie $s$ i dla każdego kolejnego kroku czasowego $t+i$ będzie działał zgodnie z polityką $\pi$.